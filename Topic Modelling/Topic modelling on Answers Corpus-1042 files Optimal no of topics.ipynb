{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6e3065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "\n",
    " \n",
    "count = 0\n",
    "answers_dict = {'narr_answers': []}\n",
    "path = r'C:\\\\Users\\\\maganti\\\\Documents\\\\INFO 5502 Chen Sir Project UNT\\\\Web Scraping Interviews\\\\Narrators Json Files-With Q&A'\n",
    "for filename in glob.glob(os.path.join(path, '*.json')): #only process .JSON files in folder.     \n",
    "    #print(filename)\n",
    "    narrators_answers_corpus = \"\"\n",
    "    with open(filename, mode = 'rb') as currentFile:\n",
    "        data = json.loads(currentFile.read())\n",
    "        try:\n",
    "            if data['transcript'] != {}:\n",
    "                for segment in data[\"transcript\"].keys():\n",
    "                    for question in data[\"transcript\"][segment]['Segment Q&A'].keys():\n",
    "                        #answers_sentiments[data[\"transcript\"][segment]['Segment Q&A'][question]] = sentiment_scores(data[\"transcript\"][segment]['Segment Q&A'][question])\n",
    "                        #print(data[\"transcript\"][segment]['Segment Q&A'][question])\n",
    "                        narrators_answers_corpus = narrators_answers_corpus + \" \" + data[\"transcript\"][segment]['Segment Q&A'][question]\n",
    "                        count = count + 1\n",
    "                        #print()\n",
    "                        #for answer in data[\"transcript\"][segment]['Segment Q&A'][question]:\n",
    "                        #    print(answer)\n",
    "                        #segment_questions_list.append(' '.join(i for i in question.split()[1:]))\n",
    "                        #print(' '.join(i for i in question.split()[1:]))\n",
    "                        #print(data['transcript'][segment]['Segment Questions'][question])\n",
    "                #print(count)    \n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    #if narrators_answers_corpus != \"\":\n",
    "    answers_dict['narr_answers'].append(narrators_answers_corpus) \n",
    "#print(len(segment_questions_list))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a0ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(answers_dict)\n",
    "df['narr_answers'] = df['narr_answers'].str.lower()\n",
    "#print(df['narr_answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246aed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maganti\\AppData\\Local\\Temp/ipykernel_14096/1017421635.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['narr_answers'] = df['narr_answers'].str.replace('[^a-zA-Z0-9 ]', '')\n"
     ]
    }
   ],
   "source": [
    "df['narr_answers'] = df['narr_answers'].str.replace('[^a-zA-Z0-9 ]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35af3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "#from stop_words import get_stop_words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import pyLDAvis#.gensim\n",
    "import pyLDAvis.gensim_models\n",
    "#from nltk.corpus import stopwords\n",
    "#stop_words = stopwords.words('english')\n",
    "#stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9bf434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "stop_words = list(get_stop_words('en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba33831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'own', 'haven', 'o', 'up', 'ain', 'before', 'to', 'and', 'be', 've', 'there', \"she's\", 'did', 'who', 'should', \"couldn't\", \"they're\", \"she'll\", 'most', \"who's\", 'mightn', 'a', 'about', 'would', 'does', 'has', 'shan', \"why's\", 'very', \"hadn't\", 'we', 'is', 'isn', 'hasn', \"they'd\", \"that's\", 'won', 'just', 'down', \"wasn't\", 'each', 'in', 'which', 'ours', 'few', \"where's\", 'being', \"aren't\", 'the', \"here's\", 'why', \"wouldn't\", \"that'll\", 'needn', 'until', 'cannot', 'no', \"i'll\", 'how', 'you', \"shouldn't\", 'ought', \"needn't\", 'myself', 'between', 'their', \"i'm\", 'herself', 'an', \"should've\", \"weren't\", \"i've\", 'only', 'will', \"when's\", \"i'd\", 'again', \"doesn't\", 'same', 'he', 'his', 'him', \"hasn't\", 'at', 'over', 'do', \"you've\", \"how's\", 'your', 'as', 'after', \"we'd\", 'could', 'hadn', \"mustn't\", 'whom', 't', 'other', 'yourselves', 'am', 'this', 'm', 'out', \"shan't\", 'themselves', 'have', 'what', 'hers', 'these', 'all', \"he'd\", \"he's\", 'll', \"what's\", 'wasn', 'yours', 'can', 'wouldn', \"she'd\", 'having', 'below', \"they'll\", 'weren', \"he'll\", 'or', 'are', 'mustn', 'were', 'if', 'when', 're', 'yourself', 'me', 'on', 'any', 'during', 'such', 'don', 'doing', 'too', \"can't\", 'further', 'i', 'shouldn', 'than', 'had', 'both', 'some', \"won't\", 'was', 'been', \"it's\", 'above', 'they', \"isn't\", 'them', 'off', 'd', 'aren', 'but', 'nor', 'my', 'our', 'theirs', 'into', 'her', 'doesn', 'where', \"haven't\", 'while', \"didn't\", 'by', \"you're\", 'its', 'those', 'from', \"we'll\", 'for', 'didn', 'himself', 'ourselves', 'so', \"we've\", 'not', \"there's\", 'itself', 'y', \"let's\", 'once', 'of', 's', 'now', 'she', 'against', 'through', 'it', 'under', 'ma', \"don't\", \"we're\", 'more', \"mightn't\", 'with', \"you'd\", 'then', \"you'll\", 'that', 'because', 'here', 'couldn', \"they've\"}\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "211\n"
     ]
    }
   ],
   "source": [
    "print((set(list(STOPWORDS)) | set(list(stop_words))))\n",
    "stopwords = list(set(list(STOPWORDS)) | set(list(stop_words)))\n",
    "print(type(list(STOPWORDS)))\n",
    "print(type((stop_words)))\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6e9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [re.sub('[^a-zA-Z0-9]+', '', word) for word in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35b350ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_narr_answers'] = df['narr_answers'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "277ff1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'for' in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "400cdc15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# loop through document list\n",
    "for i in df['clean_narr_answers']:\n",
    "    # clean and tokenize document string\n",
    "    #raw = str(i[1]).lower()\n",
    "    #tokens = tokenizer.tokenize(raw)\n",
    "    tokens = i.split()\n",
    "    # remove stop words from tokens\n",
    "    #stop_words = stopwords.words('english')\n",
    "    #stopped_tokens = [raw for raw in tokens if not raw in stop_words]\n",
    "    \n",
    "    # remove stop words from tokens\n",
    "    #stopped_tokens_new = [raw for raw in stopped_tokens if not raw in remove_words]\n",
    "    \n",
    "    # lemmatize tokens\n",
    "    \n",
    "    lemma_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # remove word containing only single char\n",
    "    new_lemma_tokens = [raw for raw in lemma_tokens if not len(raw) == 1]\n",
    "    \n",
    "    lemmatized_string = \" \".join(token for token in new_lemma_tokens)\n",
    "    \n",
    "    \n",
    "    import nltk\n",
    "    #word_data = \"The best performance can bring in sky high success.\"\n",
    "    nltk_tokens = nltk.word_tokenize(lemmatized_string)\n",
    "    #print(list(nltk.bigrams(nltk_tokens)))\n",
    "    texts.append([ele[0]+ \" \" + ele[1] for ele in list(nltk.bigrams(nltk_tokens))])\n",
    "\n",
    "# sample data\n",
    "#print(texts[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8280bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdadf4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of topics: 10\n",
      "\n",
      "Perplexity:  -15.194041991608781\n",
      "\n",
      "Coherence Score:  0.28016172792258676\n",
      "\n",
      "No of topics: 11\n",
      "\n",
      "Perplexity:  -15.636926547226299\n",
      "\n",
      "Coherence Score:  0.2528203252076886\n",
      "\n",
      "No of topics: 12\n",
      "\n",
      "Perplexity:  -16.644957643394118\n",
      "\n",
      "Coherence Score:  0.42849491116590416\n",
      "\n",
      "No of topics: 13\n",
      "\n",
      "Perplexity:  -17.265100287890604\n",
      "\n",
      "Coherence Score:  0.4108185884506593\n",
      "\n",
      "No of topics: 14\n",
      "\n",
      "Perplexity:  -17.47321067750119\n",
      "\n",
      "Coherence Score:  0.4164173228668698\n",
      "\n",
      "No of topics: 15\n",
      "\n",
      "Perplexity:  -18.1592991185747\n",
      "\n",
      "Coherence Score:  0.37651495372449817\n",
      "\n",
      "No of topics: 16\n",
      "\n",
      "Perplexity:  -18.73648076833033\n",
      "\n",
      "Coherence Score:  0.4318969468678755\n",
      "\n",
      "No of topics: 17\n",
      "\n",
      "Perplexity:  -19.43644303294838\n",
      "\n",
      "Coherence Score:  0.4829006866679104\n",
      "\n",
      "No of topics: 18\n",
      "\n",
      "Perplexity:  -19.802252534512515\n",
      "\n",
      "Coherence Score:  0.4460089000940451\n",
      "\n",
      "No of topics: 19\n",
      "\n",
      "Perplexity:  -20.42281527500499\n",
      "\n",
      "Coherence Score:  0.4519600337519683\n",
      "\n",
      "No of topics: 20\n",
      "\n",
      "Perplexity:  -20.98408493900914\n",
      "\n",
      "Coherence Score:  0.4095287100768168\n",
      "\n",
      "No of topics: 21\n",
      "\n",
      "Perplexity:  -21.44611325764543\n",
      "\n",
      "Coherence Score:  0.4341333045212824\n",
      "\n",
      "No of topics: 22\n",
      "\n",
      "Perplexity:  -22.1114457698325\n",
      "\n",
      "Coherence Score:  0.3986586919128476\n",
      "\n",
      "No of topics: 23\n",
      "\n",
      "Perplexity:  -22.530212649680568\n",
      "\n",
      "Coherence Score:  0.3690752448956073\n",
      "\n",
      "No of topics: 24\n",
      "\n",
      "Perplexity:  -23.41776482849329\n",
      "\n",
      "Coherence Score:  0.41112033606079895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coherence_score_vs_topics = {}\n",
    "for num in range(10, 25):\n",
    "    print(\"No of topics:\",num)\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=num, id2word = dictionary, passes=20)\n",
    "    #import pprint\n",
    "    #pprint.pprint(ldamodel.top_topics(corpus,topn=5))\n",
    "\n",
    "\n",
    "    from gensim.models import CoherenceModel\n",
    "\n",
    "    # Compute Perplexity\n",
    "    print('\\nPerplexity: ', ldamodel.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=ldamodel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)\n",
    "    coherence_score_vs_topics[num] = coherence_lda\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1cd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_coherence_score_df = pd.DataFrame(coherence_score_vs_topics.items(), columns = ['No.of Topics', 'Coherence score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70b7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_coherence_score_df = topic_coherence_score_df.astype({\"No.of Topics\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d250a80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(module.__version__) < minver:\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(module.__version__) < minver:\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(module.__version__) < minver:\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(module.__version__) < minver:\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:152: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(module.__version__) < minver:\n",
      "C:\\Users\\maganti\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plt.xlabel(\"No of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "ax.bar(topic_coherence_score_df['No.of Topics'],topic_coherence_score_df['Coherence score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4b27b",
   "metadata": {},
   "source": [
    ". We can observe that at 17 topics, there is good coherence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fafc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
